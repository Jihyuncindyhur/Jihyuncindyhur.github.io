<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Conference | Jihyun</title>
    <link>https://Jihyuncindyhur.github.io/tag/conference/</link>
      <atom:link href="https://Jihyuncindyhur.github.io/tag/conference/index.xml" rel="self" type="application/rss+xml" />
    <description>Conference</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><lastBuildDate>Wed, 08 Jun 2022 13:00:42 +0900</lastBuildDate>
    <image>
      <url>https://Jihyuncindyhur.github.io/images/icon_huba1290056a9aa64b0b71a1bf18bd3dc1_31701_512x512_fill_lanczos_center_3.png</url>
      <title>Conference</title>
      <link>https://Jihyuncindyhur.github.io/tag/conference/</link>
    </image>
    
    <item>
      <title>First In-Person Conference (RLDM 2022) at Brown University!</title>
      <link>https://Jihyuncindyhur.github.io/post/rldm2022/</link>
      <pubDate>Wed, 08 Jun 2022 13:00:42 +0900</pubDate>
      <guid>https://Jihyuncindyhur.github.io/post/rldm2022/</guid>
      <description>&lt;p&gt;I participated in the RLDM (Reinforcement Learning Decision-Making) conference at Brown University.&lt;/p&gt;
&lt;p&gt;First time being in Providence and in an in-person conference, it was an inspiring experience to mingle with a number of researchers from various fields including psychology, neuroscience, computer science.&lt;/p&gt;
&lt;p&gt;The conference lasted for four days, and it started with two introductory and two advanced tutorials. The following three days consisted of invited talks, contributed talks, poster sessions and workshops. The dynamics of speakers, who have been invited or selected to the conference under the same research realm called reinforcement learning (RL), helped integrate broad, diverse, and inconsistent views on the definitions, goals, and implications of RL. In the advanced tutorial by Dr. Xiaoxi Gu from Mount Sinai Hospital, the subjective utility of an agent was defined as the summation of self&amp;rsquo;s utility and other&amp;rsquo;s utility in a certain decision-making scheme (e.g., auction). As a clinical psychology researcher, it was fascinating to learn about broad implications of this approach in understanding psychiatric disorders such as nicotine addiction. Dr. Oriel HeldmanHall from Brown University presented interesting works done by Joey Heffner that in social paradigms, mood valence prediction error quantified in the 500 * 500 grid was the strongest predictor of social decisions even after accounting for reward prediction error. The arguments that self&amp;rsquo;s decision-making may be governed by other&amp;rsquo;s utility and/or mood valence beyond simple reward prediction error opened up two questions that whether the social and affective components can be modelled into the RL algorithms utilized in computer science and would significantly moderate actions in less social environments.&lt;/p&gt;
&lt;p&gt;For example, from a perspective of a non-computer scientist, the talks from the CS areas seem to be focusing mainly on maximizing cumulative reward. Some speakers defined or even questioned what &amp;lsquo;reward&amp;rsquo; should be, but most intuitively it was something that an agent tries to earn, not avoid. Then the agent is told what the reward is and asked to learn the function (policy) to maximize the cumulative reward by, for instance, minimizing the loss function. It can also be that the agent &amp;lsquo;discovers&amp;rsquo; the goal by forming a &amp;lsquo;question&amp;rsquo; itself, which was presented by Dr. Satinder Singh Baveja from DeepMind and University of Michigan. Robotics, studies on a non-human agent, focuses on mimicking human behaviors such as locating a place, performing sequential actions (e.g., finding a carrot and chopping it), or distinguishing sounds from different objects. These actions also follow the mainstream goal of maximizing cumulative reward as the robot&amp;rsquo;s actions and their underlying algorithms are reinforced by accuracy measures - if the robot successfully finds the given location two out of ten attempts exploiting a certain policy, it will update the policy to minimize the loss (low accuracy) to reach higher hit rates. Even though the classic RL algorithms lead to successful reward maximization, these goals and policies did not necessarily account for the influences of other agents and emotions. There might be some frameworks modelling cooperative behaviors in CS, but it is hard to find any aspects of mood being included in the non-human agent modeling.&lt;/p&gt;
&lt;p&gt;Due to the complicated and volatile nature of the affective components, such trend in CS is totally understandable as it is even difficult to investigate how moods vary and affect decision-making and learning in human beings. Any learning agents can be told or can form by itself the question (&amp;ldquo;what to achieve?&amp;quot;) in a given state, and it will decide upon the policy consistent with the question. However, human actions can be swayed by momentary moods. Even if we know the exact goal, we sometimes choose the actions against it because we are feeling too positive or too negative. This example might imply the role of mood extremeness on decision-making, but it is just one of the potential hypotheses.&lt;/p&gt;
&lt;p&gt;I&amp;rsquo;m not sure if it is advantageous to take moods into account for modelling a RL agent in the CS area. One thing that this conference has taught me though is a clear need for incorporating affective components into computational psychiatry research, especially for better understanding mood disorders like depression and anxiety. Even in the environments that less involve others (or less social), individuals with depression or anxiety often face situations that their decisions are strongly influenced by their mood states, leading to a vicious cycle of psychiatric symptoms. These moods, however, might not be captured well within current lab-based decision-making tasks, because of the moods&#39; contextual or even voluntary representations over choices. I would like to clarify &amp;lsquo;the contextual and voluntary&amp;rsquo; representations in another blog post to keep the main theme in this post.&lt;/p&gt;
&lt;p&gt;To conclude, among many factors affecting decision-making and learning, mood-related factors are crucial. Through this conference, my research directions have been updated to deeply account for moods and emotions in less social but clinically relevant states (e.g., being alone in a room). For one final remark, there is a therapeutic technique called validation. Validation is often achieved by unconditionally accepting naturally occurring emotions. Basically helping clients feel and recognize that it is very natural for them to feel such emotions in the given situations. When serving as a clinician, I thought this unconditional acceptance by the clients themselves is one of the most crucial keys for alleviating depressive and anxious symptoms. This abstract concept of validation might be better understood through applying computational modeling in research. One possible way could be developing a computational model to tract the degree to which individuals with depression can validate their feelings that occur during a decision-making task and how it impacts their choices. This sounds like one of my long-term research goals :)&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
